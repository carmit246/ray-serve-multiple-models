apiVersion: ray.io/v1alpha1
kind: RayService
metadata:
  name: serve-multiple-models
spec:
  serveConfigV2: |
    applications:
      - name: llm_app
        route_prefix: /llm
        import_path: multiple_models_demo.llm_app
        deployments:
          - name: FlanT5Deployment
            ray_actor_options:
              num_cpus: 2
              runtime_env: {}
            autoscaling_config:
              target_ongoing_requests: 1
              max_ongoing_requests: 10
              min_replicas: 1
              max_replicas: 10
              upscale_delay_s: 1
      - name: sentiment_app
        route_prefix: /sentiment
        import_path: multiple_models_demo.sentiment_app
        deployments:
          - name: SentimentAnalysisDeployment
            ray_actor_options:
              num_cpus: 1
              runtime_env: {}
            autoscaling_config:
              target_ongoing_requests: 1
              max_ongoing_requests: 10
              min_replicas: 1
              max_replicas: 10
              upscale_delay_s: 1
  rayClusterConfig:
    rayVersion: "2.10.0"
    headGroupSpec:
      rayStartParams:
        dashboard-host: "0.0.0.0"
        include-dashboard: "true"
        num-cpus: '0'
      serviceType: ClusterIP
      template:
        spec:
          containers:
            - name: ray-head
              image: ray_multiple_models:1.0
              ports:
                - containerPort: 8000
                  name: serve
                - containerPort: 8265
                  name: dashboard
                - containerPort: 8080
                  name: metrics
              env:
                - name: SERVE_PORT
                  value: "8000"
    workerGroupSpecs:
      - groupName: worker-group
        minReplicas: 1
        maxReplicas: 2
        rayStartParams: {}
        template:
          spec:
            containers:
              - name: ray-worker
                image: ray_multiple_models:1.0
